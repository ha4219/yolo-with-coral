{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a26e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from model import Model\n",
    "from utils import Colors, get_image_tensor, xywh2xyxy, xywh2xyxy, box_iou, ap_per_class\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "images = glob('/data/images/val/*')\n",
    "labels = glob('/data/labels/val/*')\n",
    "\n",
    "nc = 1\n",
    "\n",
    "stats = []\n",
    "\n",
    "iouv = np.linspace(0.5, 0.95, 10)  # iou vector for mAP@0.5:0.95\n",
    "niou = iouv.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c812b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(detections, labels, iouv):\n",
    "    \"\"\"\n",
    "    Return correct predictions matrix. Both sets of boxes are in (x1, y1, x2, y2) format.\n",
    "    Arguments:\n",
    "        detections (Array[N, 6]), x1, y1, x2, y2, conf, class\n",
    "        labels (Array[M, 5]), class, x1, y1, x2, y2\n",
    "    Returns:\n",
    "        correct (Array[N, 10]), for 10 IoU levels\n",
    "    \"\"\"\n",
    "    correct = np.zeros((detections.shape[0], iouv.shape[0])).astype(bool)\n",
    "    iou = box_iou(labels[:, 1:], detections[:, :4])\n",
    "    correct_class = labels[:, 0:1] == detections[:, 5]\n",
    "    for i in range(len(iouv)):\n",
    "        x = np.where((iou >= iouv[i]) & correct_class)  # IoU > threshold and classes match\n",
    "        if x[0].shape[0]:\n",
    "            matches = np.cat((np.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()  # [label, detect, iou]\n",
    "            if x[0].shape[0] > 1:\n",
    "                matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
    "                # matches = matches[matches[:, 2].argsort()[::-1]]\n",
    "                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
    "            correct[matches[:, 1].astype(int), i] = True\n",
    "    return np.array(correct, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f536e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:EdgeTPUModel:Confidence threshold: 0.25\n",
      "INFO:EdgeTPUModel:IOU threshold: 0.45\n",
      "INFO:EdgeTPUModel:Loaded 1 classes\n",
      "INFO:EdgeTPUModel:Successfully loaded /home/mendel/code/yolo-with-coral/models/320/s.tflite\n"
     ]
    }
   ],
   "source": [
    "model = Model('models/320/s.tflite', 'data/tree.yaml', conf_thresh=0.25, iou_thresh=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57512891",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xywh2xyxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8741/1958282046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/yolo-with-coral/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, with_nms)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mtstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mnms_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magnostic_nms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_det\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/yolo-with-coral/nms.py\u001b[0m in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Box (center x, center y, width, height) to (x1, y1, x2, y2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxywh2xyxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# Detections matrix nx6 (xyxy, conf, cls)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xywh2xyxy' is not defined"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    img, shapes = get_image_tensor(cv2.imread(img), 320)\n",
    "    \n",
    "    print(model.forward(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = []\n",
    "for label in labels:\n",
    "    with open(label, 'r') as f:\n",
    "        lines = []\n",
    "        for line in f.readlines():\n",
    "            lines.append(list(map(float, line.strip().split())))\n",
    "        if lines:\n",
    "            lines = np.array(lines)\n",
    "        else:\n",
    "            lines = np.ndarray((0, 5))\n",
    "        y.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd315a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [get_image_tensor(image, model.input_size[0]) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for (full_image, net_image, pad), (label) in zip(x, y):\n",
    "    pred = model.forward(net_image)\n",
    "    preds.append(pred)\n",
    "    labels.append(label)\n",
    "    print('pred',pred)\n",
    "    print('label',label)\n",
    "#     print(model.get_scaled_coords(pred[0][:,:4], full_image, pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d05bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_image.shape[:2], pred[0][:, :4], [2160, 3840], shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
